# Lesson: Advanced Interaction Technologies & Applications

### First and Last Name: Dimitris Kokkinis
### University Registration Number: dpsd19054
### GitHub Personal Profile: <a href="https://github.com/kokkinis19054">kokkinis19054</a>
### Advanced Interaction Tecnologies & Applications Github Personal Repository: <a href="https://github.com/kokkinis19054/Advanced-Interaction-Tecnologies-Applications-Individual-Assignment">AITA GitHub Profile</a> 

# Introduction
Σύμφωνα με τα βήματα κατέβασα την εκδοχή 3.5.4 του Processing για να αρχίσω να δουλέυω πάνω στο κάθε ζητούμενο που μου ανατέθηκε.

# Summary


# 1st Deliverable
Δημιουργούσα και ένα φάκελο data σε κάθε αρχείο που το ζητούσε μαζί με το .pde του. <br> 
Video Capture <br>
Έτρεξα το <a href="http://learningprocessing.com/examples/chp16/example-16-01-Capture">Example 16-1</a> και κατέβασα την βιβλιοθήκη "video library for Processing..." αλλά μου εμφάνιζε το παρακάτω error<br>
![VideoCaptureError](https://user-images.githubusercontent.com/100956242/200703744-3e57e91a-3ca5-4a56-8f65-996ba1b563f4.png)

Record Video<br>
Σε συνδιασμό των παραδειγμάτων 16-4 και 16-5 έκανα το Exercise 16-2 και έβαλα ένα δικό μου βίντεο από ένα αρχείο μου<br>
![RecordedVideoDONE](https://user-images.githubusercontent.com/100956242/200704645-11f197e7-6e12-4e8b-b0f1-eccec46f7742.png)

Qr Code  <br>
Διάβασα το προτεινόμενο tutorial και κατέβασα την QR Code Library. Χρισημοποίησα τον κώδικα που είχε το tutorial σε συνδιασμό με κώδικα για να εμφανιστεί η εικόνα. <br>
![QR Code](https://user-images.githubusercontent.com/100956242/200705272-cd169947-fcf1-4e89-ac7b-4002cba4f766.png)

QR Code - Camera Read <br>
Χρισημοποίησα το QRCodeExample από την βιβλιοθήκη και έτρεξα τον κώδικα.<br>

![QR CODE READ](https://user-images.githubusercontent.com/100956242/200707028-33c3c3ce-65ef-4897-b714-431d8a5a863d.png)


AR <br>
Αφού διάβασα το
<a href="https://medium.com/a-curious-beginners-guide-to-building-your-first/my-first-ar-exploration-with-processing-71ffaf3e7418">προτεινόμενο παράδειγμα</a> κατέβασα την βιβλιοθίκη  NyARToolkit. Μέσα στον φάκελο data της βιβλιοθήκης έβαλα την εικόνα που ήθελα να εφανίζεται διαβάζοντας το QR. Στο συγκεκριμένο τασκ μου εμφανιζόταν το παρακάτω error σε κάθε προσπάθεια που έκανα για να το λύσω. <br>
![AR](https://user-images.githubusercontent.com/100956242/200708009-9c598f04-96e8-400e-be0f-aa9354a49844.png)


# 2nd Deliverable
Background Removal <br>
Δημιούργησα ένα φάκελο data για το πρωτο ζητούμενο με την εικόνα που το ζητούσε μαζί με το .pde του.. <br>
Διάβασα το παράδειγμα <a href="http://learningprocessing.com/examples/chp16/example-16-12-Capture">Example 16-12</a> από το βιβλίο Learning Processing,2nd Edition, αντέγραψα τον κώδικα, έκανα κάποιες μετατροπές πάνω σε αυτόν (άλλαξα το size και το έκανα ίδιο με την εικόνα που εισήγαγα, έκανα το threshold 20).Τέλος, έκανα πειράματα σε έναν πράσινο τοίχο του Πανεπηστημιού μας έτσι ώστε όπου υπήρχε πράσινο χρώμα στο background να εμφανίζει την εικόνα που εισήγαγα. <br>

Motion Detection <br>
Πρώτα διάβασα τα παραδείγματα <a href="http://learningprocessing.com/examples/chp16/example-16-11-Capture">Example 16-11</a> και <a href="http://learningprocessing.com/examples/chp16/example-16-13-Capture">Example 16-13</a> και στη συνέχεια επεξεργάστηκα την άσκηση 16-7, αυτό που έκανα δηλαδή ηταν να ορίσω μέγεθος, χρώμα και σχήμα.Τέλος, έτρεξα το processing και εμφανιζιζόταν ένα κίτρινο ορθογώνιο 'οπυ ακολουθούσε την κίνηση του χεριού μου. <br>


Background Substraction <br>
Πρόσθεσα την βιβλιοθήκη "OpenCV for Processing", στη συνέχεια επεξεργάστηκα τον κώδικα "BackgroundSubstraction" , έκανα κάποιες μετατροπές στον κώδικα, όρισα το χρώμα  και έτρεξα το processing.Ερώτηση: Ποιά είναι τα πλεονεκτήματα και μειονεκτήματα της έτοιμης βιβλιοθήκης έναντι του κώδικα από το πρώτο ερώτημα? Τα πλεονέκτηματα με την χρήση της βιβλιοθήκης αυτής ηταν η μεγαλύτερη ευκολία στην διαδικασία και στον εντοπισμό των κινήσεων του σωματος. Τα μειονεκτήματα της ήταν η δυσκολία στην εγκατάσταση της. <br>

Object Tracking <br>
Διάβασα το παράδειγμα <a href="http://learningprocessing.com/examples/chp16/example-16-11-Capture">Example 16-11</a>  από το βιβλίο Learning Processing, 2nd Edition, αντέγραψα υον κώδικα και μετά το τρεξα στο Processing. Υστερα πρόσθεσα τον κώδικα από το παράδειγμα <a href="http://learningprocessing.com/examples/chp16/example-9-8-Capture">Example 9-8</a> και άλλαξα κάποιες εντολές για να δουλεύει με τον κώδικα του παραδείγματος <a href="http://learningprocessing.com/examples/chp16/example-16-11-Capture">Example 16-11</a>. Έτσι, αυτό που εμφανιζόταν στην οθόνη είναι εκεί που έκανε tracking ένα αντικείμενο σε κίτρινη απόχρωση να αφήνει μία μαυροκόκκινη ουρά πίσω του.Ερώτηση: Σε σχέση με το παραδοσιακό ποντίκι ποια είναι τα πλεονεκτήματα και ποια τα μειονεκτήματα αυτής της τεχνικής ελέγχου ενός ή περισσότερων σημείων σε μια οθόνη? Τα πλεονεκτήματα είναι ότι απαιτείται μόνο η ύπαρξη κάμερας, οτί μπορεί να γίνει και από απόσταση και ότι υπάρχει μεγαλύτερη ευκολία πρόσβασης, ενώ τα  μειωνεκτήματα είναι οτί δεν είναι είναι τόσο αποτελεσματικό, κολλάει μερικές φορές και υπάρχουν περισσότεροι περιορισμοί. <br>
![2022-12-16 (22)](https://user-images.githubusercontent.com/100956242/208106711-8597ed7c-8b57-473b-9062-62b89b07f278.png) <br>

![2022-12-16 (7)](https://user-images.githubusercontent.com/100956242/208113480-eec4b8e0-b2f9-446d-9ca3-e818e0f70a06.png)


# 3rd Deliverable 
Αρχικά, έκανα την εγκατάσταση της εφαρμογής reacTIVision vision engine στον υπολογιστή μου, στη συνέχεια εγκατέστησα την βιβλιοθήκη reacTIVision, την τοποθέτησα στο folder του Processing. <br>
![2023-01-07 (1)](https://user-images.githubusercontent.com/100956242/211154004-23b49b75-ced7-4ba7-a4d4-371d3e467f47.png) <br>
 Κατέβασα το TUIO Simulator και μετά εκτέλεσα το TuioDemo. Στην αρχή ήταν μόνο άσπρη η εικόνα και όταν άρχισα να βάζω τα διάφορα σχήματα μέσα στον κύκλο που εμφανίζεται στο simulator, εμφανίστηκαν τα αντίστοιχα μάυρα κουτάκια με τους αριθμούς στις θέσεις που τα τοποθετούσα και οποιοδήποτε κίνηση έκανα στο simulator, το ίδιο συνέβαινε και στο TuioDemo. <br>
 ![2023-01-07 (4)](https://user-images.githubusercontent.com/100956242/211156296-1c94c348-e068-4d8b-a59e-add5852193f5.png) <br>
 ![2023-01-07 (5)](https://user-images.githubusercontent.com/100956242/211156317-496689fe-c07b-4f6f-8971-a5dcc28d5f52.png) <br>

Μετά την παρακολούθηση κάποιων βίντεο από εδώ (https://www.youtube.com/results?search_query=TUIO+and+processing), κατάλαβα τι έπρεπε να κάνω με βάση το παράδειγμα κώδικα του TUIO demo και έκανα τις εξής μετατροπές στον κώδικα έτσι ώστε να εντοπίζει η μηχανή υπολογιστικής όρασης reacTIVision τους διάφορους κωδικούς που χρησιμοποιήσα προβάλοντας τους από το κινητό μου και να εμφανίζει αντίστοιχα τις δύο εικόνες (όπου δημιούργησα και ένα φάκελο data στον φάκελο του processing στον υπολογιστή μου και έπειτα πρόσθεσα το αρχείο με τις εικόνες μέσα στο processing). Ύστερα, ήθελα να πρσαρμώσω κάποιους από τους κωδικούς να έχουν συγκερκιμένες λειτουργίες και έτσι βρήκα ένα παράδειγμα από το (https://forum.processing.org/two/discussion/4991/help-with-detecting-fiducial-markers) και στην συνέχεια μπήκα στο (https://processing.org/) και έψαξα κάποια φίλτρα μπαίνοντας στο Documentation-Reference-Image-Pixels και για το πως αυξομειώνω μεγέθη στο Documentation-Reference-Transform. Τέλος, προσάρμοσα αυτά τα παραδείγματα με τις ανάλογες μετατροπές στον αρχικό κώδικα και τον εκτέλεσα με αποτέλεσμα: <br>
Το ID=5 εμφανίζει την (CAT2.jpg) <br>

 ![CAT5 (2)](https://user-images.githubusercontent.com/100956242/211202241-1ddd536b-681a-4703-9254-113a441cb701.png) <br> 

Το ID=6 εμφανίζει την (CAT1.jpg) <br>
 ![CAT6 (2)](https://user-images.githubusercontent.com/100956242/211202277-a3c7f5f0-d527-40bd-a629-587a64d394f8.png) <br>

Το ID=5 μαζί με ID=3 και αντίστοιχα το ID=6 με ID=3 κάνει (Posterize) <br>
![CAT5 POSTERIZE](https://user-images.githubusercontent.com/100956242/211202336-5ca9122a-d03d-4ad3-9369-b740ad766a96.png) <br>
![CAT6 POSTERIZE](https://user-images.githubusercontent.com/100956242/211202348-29bcb6eb-00f9-423c-a12a-9a1f3bd768f7.png) <br>

Το ID=5 μαζί με ID=4 και αντίστοιχα το ID=6 με ID=4 κάνει (Blur) <br>
![CAT5 BLUR](https://user-images.githubusercontent.com/100956242/211202382-f3eda7ff-ab38-456d-9d6b-7bcc8cb85901.png) <br>
![CAT6 BLUR](https://user-images.githubusercontent.com/100956242/211202392-9b5e1153-f324-48e7-b4f0-99f59c7643f4.png) <br>

Το ID=6 μαζί με ID=2 και αντίστοιχα με ID=5 αλλάζει το (Scale) <br>
![CAT6 SCALE](https://user-images.githubusercontent.com/100956242/211202446-9af16386-477c-4010-8da8-31dc971bb098.png) <br>

<br>
Σε ποια φάση της σχεδίασης και ανάπτυξης του υλικό/λογισμικού της διάδρασης θα διαλέγατε την κανονική κάμερα ή τον προσομοιωτή?
Η αλήθεια είναι ότι για την αναγνώριση των κωδικών fiducial-markers και των ιδιοτήτων που έχω θέσει στον καθένα μέσω του simulator είναι ευκολότερη, γρηγορότερη και πιο αξιόπιστη διαδικασία μιας και που μέσω κάμερας η ευκρίνεια μπορεί να μην είναι τόσο δυνατή για να πετύχει εξαρχής. Από την άλλη, θα προτιμούσα την κάμερα για τον τελικό έλεγχο και για την διάδραση του χρήστη με αυτήν καθώς θεωρώ την δοκιμή και πιο ευχάριστη από ότι με τον simulator.


# Bonus 


# Conclusions


# Sources
Tutorial Tuio + reacTIVision en processing: https://youtu.be/qKXlI4zAMAY <br>
Tutorial Tuio Simulator Processing: https://youtu.be/tJ0aZzST-N4 <br>
Example: https://forum.processing.org/

